{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMvAhdnYWpIf"
   },
   "source": [
    "# **Volcengine Agent Development Kit æ•™ç¨‹**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp8ynUiFXIHi"
   },
   "source": [
    "## ä»‹ç»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mS7BD6K0Xkr9"
   },
   "source": [
    "VeADK æ˜¯ç”±ç«å±±å¼•æ“æ¨å‡ºçš„ä¸€å¥—é¢å‘æ™ºèƒ½ä½“å¼€å‘çš„å…¨æµç¨‹æ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºå¼€å‘è€…æä¾›é¢å‘æ™ºèƒ½ä½“æ„å»ºã€äº‘ç«¯éƒ¨ç½²ã€è¯„æµ‹ä¸ä¼˜åŒ–çš„å…¨æµç¨‹å¼€å‘ã€‚\n",
    "\n",
    "ç›¸è¾ƒäºç°æœ‰çš„æ™ºèƒ½ä½“å¼€å‘æ¡†æ¶ï¼ŒVeADK å…·å¤‡ä¸ç«å±±å¼•æ“äº§å“ä½“ç³»æ·±åº¦èåˆçš„ä¼˜åŠ¿ï¼Œå¸®åŠ©å¼€å‘è€…æ›´é«˜æ•ˆåœ°æ„å»ºä¼ä¸šçº§ AI æ™ºèƒ½ä½“åº”ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw8bJmYEXJgg"
   },
   "source": [
    "## é…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDzTOuunaSPB"
   },
   "source": [
    "### å®‰è£… VeADK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAZ40k9uXhm6"
   },
   "outputs": [],
   "source": [
    "%pip install veadk-python --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0IY257hncOB"
   },
   "source": [
    "> å¦‚æœä½ åœ¨æœ¬åœ°ä½¿ç”¨çš„ç»ˆç«¯æ˜¯`zsh`ï¼Œå½“ä½ è¿›è¡Œ`pip install`æ—¶ï¼Œ**ä¾èµ–åŒ…åç§°åº”å½“è¢«åŒå¼•å·åŒ…è£¹èµ·æ¥**ï¼Œå¦åˆ™ä¼šè§£æé”™è¯¯ã€‚\n",
    ">\n",
    "> ä½ åº”å½“ä½¿ç”¨ï¼š\n",
    "> ```bash\n",
    "> pip install \"veadk-python\"\n",
    "> pip install \"agent-pilot-sdk>=0.0.9\"\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-0A36gmXfJj"
   },
   "source": [
    "### ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6o2LmjGXdb2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MODEL_AGENT_NAME\"] = \"doubao-seed-1-6-250615\"  # <-- ç«å±±æ–¹èˆŸå¤§æ¨¡å‹åç§°\n",
    "\n",
    "os.environ[\"MODEL_AGENT_API_KEY\"] = \"\"  # <-- è®¾ç½®ç«å±±æ–¹èˆŸçš„API KEYæ¥è®¿é—®æ¨¡å‹\n",
    "\n",
    "os.environ[\"LOGGING_LEVEL\"] = \"ERROR\"  # <-- è°ƒæ•´æ—¥å¿—ç­‰çº§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCw_PEP5X-fc"
   },
   "source": [
    "## Agent æ„å»º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rtLXYn4aoQt"
   },
   "source": [
    "### å¿«é€Ÿå¼€å§‹\n",
    "\n",
    "åˆå§‹åŒ–Agentè¿‡ç¨‹ä¸­ï¼Œä½ å¯ä»¥ä¸ä¼ å…¥ä»»ä½•å‚æ•°ï¼ŒVeADK ä¼šè‡ªåŠ¨è¯»å–ç¯å¢ƒå˜é‡ã€‚æŸ¥çœ‹[å®Œæ•´çš„ Agent å‚æ•°](https://volcengine.github.io/veadk-python/agent/agent#%E9%80%89%E9%A1%B9)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8yM5QKjYAVo",
    "outputId": "239b8f05-25a5-4266-8142-a1204fefe031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's fantastic to connect with a fellow Agent developer. As someone working in this space, you might be building Agents for specific domains like automation, data processing, or even multi-modal interaction. Are you currently focused on a particular projectâ€”maybe refining an existing Agent's capabilities, solving integration challenges (like tool APIs or workflow logic), or exploring new use cases? If you have questions about architecture design, optimizing response efficiency, or best practices for Agent-human collaboration, feel free to shareâ€”Iâ€™d love to help brainstorm or troubleshoot! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent\n",
    "\n",
    "agent = Agent()  # åˆå§‹åŒ– Agent\n",
    "\n",
    "response = await agent.run(\"ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€å Agent å¼€å‘è€…ã€‚\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnX7pSDFbuYY"
   },
   "source": [
    "### ä½¿ç”¨ Runner\n",
    "\n",
    "ç”Ÿäº§ç¯å¢ƒä¸‹çš„æœ€ä½³å®è·µï¼šä½¿ç”¨`Runner`æ¥è¿è¡Œ Agentï¼Œé€šè¿‡`app_name`ã€`user_id`ä»¥åŠ`session_id`ä»¥å®ç°å¤šç§Ÿæˆ·éš”ç¦»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYC9Z0_Yb-SX",
    "outputId": "69d80b01-a820-4e62-e91d-d96682c3073a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ è¿™ä½ Agent å¼€å‘è€…ï¼å¼€å‘æ™ºèƒ½ Agent ç¡®å®æ˜¯ä¸€é¡¹å……æ»¡æŒ‘æˆ˜åˆæå…·åˆ›é€ åŠ›çš„å·¥ä½œå‘¢ã€‚ä½ ç›®å‰æ˜¯åœ¨å¼€å‘æŸä¸ªç‰¹å®šé¢†åŸŸçš„ Agentï¼ˆæ¯”å¦‚æ•°æ®å¤„ç†ã€è‡ªåŠ¨åŒ–ä»»åŠ¡ã€æ™ºèƒ½äº¤äº’ç­‰ï¼‰ï¼Œè¿˜æ˜¯åœ¨æ„å»º Agent æ¡†æ¶æˆ–å·¥å…·å‘¢ï¼Ÿå¦‚æœåœ¨å¼€å‘è¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•é—®é¢˜â€”â€”æ¯”å¦‚æ•°æ®ç§‘å­¦æ¨¡å—çš„è®¾è®¡ã€ä»£ç å®ç°ï¼ˆPython/JavaScript ç­‰ï¼‰ã€æ–‡æ¡£æ’°å†™ï¼Œæˆ–è€… Agent ä¸å¤–éƒ¨å·¥å…·çš„é›†æˆç­‰ï¼Œéƒ½å¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¾ˆä¹æ„å’Œä½ ä¸€èµ·æ¢è®¨è§£å†³æ–¹æ¡ˆï¼ ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "agent = Agent()\n",
    "short_term_memory = ShortTermMemory()  # çŸ­æœŸè®°å¿†ä»£è¡¨çš„æ˜¯ç”¨æˆ·å•æ¬¡ä¼šè¯å†…çš„å¯¹è¯è®°å½•\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨ runner ä¸­çš„`run`æ–¹æ³•æ¥è°ƒç”¨ Agent\n",
    "response = await runner.run(\n",
    "    messages=\"ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€å Agent å¼€å‘è€…ã€‚\", session_id=session_id\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WVpEzN_ale6"
   },
   "source": [
    "### ä½¿ç”¨ Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3yLU8WndkTj"
   },
   "source": [
    "åˆå§‹åŒ– Agent æ—¶ï¼Œä½ å¯ä»¥ä½¿ç”¨`tools`å­—æ®µæ¥æŒ‚è½½å·¥å…·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYoeTLH1c5nG",
    "outputId": "58b57f13-68b6-45dd-f492-7b3abccd268b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŒ—äº¬ç°åœ¨å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "from veadk.tools.demo_tools import get_city_weather\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "agent = Agent(tools=[get_city_weather])\n",
    "short_term_memory = ShortTermMemory()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "response = await runner.run(messages=\"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", session_id=session_id)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWGfvP7peFPe"
   },
   "source": [
    "ä½ è¿˜å¯ä»¥ä½“éªŒ**ç«å±±å¼•æ“æä¾›çš„å¼ºå¤§æœç´¢èƒ½åŠ›**ï¼Œä¾‹å¦‚ä½¿ç”¨`web_search`å’Œ`VeSearch`å·¥å…·ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDtvFNcAy9FK"
   },
   "source": [
    "ä½¿ç”¨`web_search`å·¥å…·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HxUlgqZAeKUn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# è®¾ç½®ç«å±±å¼•æ“ AK å’Œ SK æ¥ä½¿ç”¨ web_search å·¥å…·\n",
    "os.environ[\"VOLCENGINE_ACCESS_KEY\"] = \"\"\n",
    "os.environ[\"VOLCENGINE_SECRET_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZuToGTbOeTEB",
    "outputId": "e360b132-1bff-4ed4-bf66-7910cd95d164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ®åŒ—äº¬å¸‚ç”Ÿæ€ç¯å¢ƒç›‘æµ‹ä¸­å¿ƒæ•°æ®ï¼Œ**ä»Šå¤©ï¼ˆ8æœˆ15æ—¥ï¼‰åŒ—äº¬ç©ºæ°”è´¨é‡æŒ‡æ•°ï¼ˆAQIï¼‰ä¸º40ï¼Œç­‰çº§ä¸ºä¼˜**ã€‚å…·ä½“æ±¡æŸ“ç‰©æµ“åº¦å¦‚ä¸‹ï¼š  \n",
      "- PM2.5ï¼š38 Î¼g/mÂ³  \n",
      "- PM10ï¼š38 Î¼g/mÂ³  \n",
      "- O3ï¼š24 Î¼g/mÂ³  \n",
      "- NO2ï¼š7 Î¼g/mÂ³  \n",
      "- SO2ï¼š1 Î¼g/mÂ³  \n",
      "- COï¼š0.6 mg/mÂ³  \n",
      "\n",
      "**å»ºè®®æªæ–½**ï¼šå„ç±»äººç¾¤å¯æ­£å¸¸æ´»åŠ¨ã€‚  \n",
      "\n",
      "æ­¤å¤–ï¼Œæœªæ¥ä¸‰å¤©ï¼ˆ16-18æ—¥ï¼‰ç©ºæ°”è´¨é‡é¢„è®¡ç»´æŒä¼˜è‡³è‰¯ç­‰çº§ï¼Œé¦–è¦æ±¡æŸ“ç‰©ä¸ºè‡­æ°§ï¼ˆO3ï¼‰ï¼Œéœ€æ³¨æ„å¤å­£è‡­æ°§æ±¡æŸ“é˜²æŠ¤ã€‚\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "from veadk.tools.builtin_tools.web_search import web_search\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "agent = Agent(tools=[web_search])\n",
    "short_term_memory = ShortTermMemory()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "response = await runner.run(messages=\"åŒ—äº¬ä»Šå¤©çš„ç©ºæ°”è´¨é‡\", session_id=session_id)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoTXmqz8zAvp"
   },
   "source": [
    "å°è¯•ä½¿ç”¨`VeSearch`å·¥å…·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YhYG3VxpzE8i"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# è®¾ç½® vesearch å·¥å…·çš„ ENDPOINT å’Œ API KEY\n",
    "os.environ[\"TOOL_VESEARCH_ENDPOINT\"] = \"\"\n",
    "os.environ[\"TOOL_VESEARCH_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "948i9Be8zIvr",
    "outputId": "ad556c58-f48a-4306-b812-969f4d38148a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### åŒ—äº¬æœªæ¥ä¸ƒå¤©å¤©æ°”é¢„æŠ¥ï¼ˆ2025å¹´8æœˆ16æ—¥-8æœˆ22æ—¥ï¼‰  \n",
      "- **8æœˆ16æ—¥ï¼ˆå‘¨å…­ï¼‰**ï¼šé›·é˜µé›¨ï¼Œ24-31â„ƒï¼Œå—é£1çº§ï¼Œæ¹¿åº¦82%ï¼Œç´«å¤–çº¿æŒ‡æ•°4ï¼Œç©ºæ°”è´¨é‡è‰¯ã€‚  \n",
      "- **8æœˆ17æ—¥ï¼ˆå‘¨æ—¥ï¼‰**ï¼šé›·é˜µé›¨ï¼Œ24-30â„ƒï¼Œä¸œé£1çº§ï¼Œæ¹¿åº¦85%ï¼Œç´«å¤–çº¿æŒ‡æ•°4ï¼Œç©ºæ°”è´¨é‡è‰¯ã€‚  \n",
      "- **8æœˆ18æ—¥ï¼ˆå‘¨ä¸€ï¼‰**ï¼šé˜´è½¬é›·é˜µé›¨ï¼Œ24-30â„ƒï¼Œå—é£1çº§ï¼Œæ¹¿åº¦89%ï¼Œç´«å¤–çº¿æŒ‡æ•°4ï¼Œç©ºæ°”è´¨é‡è‰¯ã€‚  \n",
      "- **8æœˆ19æ—¥ï¼ˆå‘¨äºŒï¼‰**ï¼šé›·é˜µé›¨ï¼Œ24-29â„ƒï¼Œè¥¿åŒ—é£1çº§ï¼Œæ¹¿åº¦86%ï¼Œç´«å¤–çº¿æŒ‡æ•°3ï¼Œç©ºæ°”è´¨é‡è‰¯ã€‚  \n",
      "- **8æœˆ20æ—¥ï¼ˆå‘¨ä¸‰ï¼‰**ï¼šé˜´è½¬é›·é˜µé›¨ï¼Œ24-31â„ƒï¼Œä¸œå—é£1çº§ï¼Œæ¹¿åº¦86%ï¼Œç´«å¤–çº¿æŒ‡æ•°4ï¼Œç©ºæ°”è´¨é‡è‰¯ã€‚  \n",
      "- **8æœˆ21æ—¥ï¼ˆå‘¨å››ï¼‰**ï¼šå°é›¨è½¬é˜´å¤©ï¼Œ24-32â„ƒï¼Œè¥¿å—é£1çº§ï¼Œæ¹¿åº¦80%ï¼Œç´«å¤–çº¿æŒ‡æ•°3ï¼Œç©ºæ°”è´¨é‡ä¿¡æ¯æš‚ç¼ºã€‚  \n",
      "- **8æœˆ22æ—¥ï¼ˆå‘¨äº”ï¼‰**ï¼šæ™´ï¼Œ22-30â„ƒï¼Œå—é£1çº§ï¼Œæ¹¿åº¦69%ï¼Œç´«å¤–çº¿æŒ‡æ•°5ï¼Œç©ºæ°”è´¨é‡ä¿¡æ¯æš‚ç¼ºã€‚  \n",
      "\n",
      "### é‡è¦æç¤º  \n",
      "- **é¢„è­¦ä¿¡æ¯**ï¼š15æ—¥å‚æ™šè‡³16æ—¥æ—©æ™¨æœ‰æš´é›¨ï¼ˆå°æ—¶é›¨å¼ºå¯è¾¾30æ¯«ç±³ä»¥ä¸Šï¼‰åŠé›·ç”µï¼Œå±€åœ°ä¼´7çº§çŸ­æ—¶å¤§é£ï¼Œå±±åŒºéœ€é˜²èŒƒå±±æ´ªã€æ³¥çŸ³æµç­‰æ¬¡ç”Ÿç¾å®³ã€‚  \n",
      "- **ç”Ÿæ´»å»ºè®®**ï¼šæœªæ¥ä¸‰å¤©ï¼ˆ15-17æ—¥ï¼‰ä¸é€‚å®œæ´—è½¦å’Œæˆ·å¤–æ´»åŠ¨ï¼Œéœ€éšèº«æºå¸¦é›¨å…·ï¼Œæ³¨æ„é˜²é›·é˜²é›¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "from veadk.tools.builtin_tools.vesearch import vesearch\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "agent = Agent(tools=[vesearch])\n",
    "short_term_memory = ShortTermMemory()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "response = await runner.run(messages=\"æœªæ¥ä¸ƒå¤©åŒ—äº¬çš„å¤©æ°”\", session_id=session_id)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlLT8MMTbLmd"
   },
   "source": [
    "### çŸ­æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rzy1X8lXGLk"
   },
   "source": [
    "ä½ å¯ä»¥åˆå§‹åŒ–ä¸€ä¸ª`Local`æ¨¡å¼çš„çŸ­æœŸè®°å¿†ï¼Œå®ƒåªä¼šå­˜åœ¨ä¸å†…å­˜ä¸­ã€‚å…¶ä»…åœ¨ä¸€æ¬¡è°ƒç”¨ä¸­ä¼šæœ‰è®°å¿†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8L9ORClwXWbj",
    "outputId": "9ab3735c-2ec7-4b2d-fadc-1dd4cd0dc398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å½“ç„¶è®°å¾—ï¼ä½ å«VeADKï¼Œå¾ˆé«˜å…´å†æ¬¡å’Œä½ äº¤æµ ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "agent = Agent()\n",
    "short_term_memory = ShortTermMemory(\n",
    "    backend=\"local\"\n",
    ")  # æŒ‡å®š local åç«¯ï¼Œæˆ–ç›´æ¥ ShortTermMemory()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "response = await runner.run(\n",
    "    messages=[\"æˆ‘å«VeADK\", \"ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆå—ï¼Ÿ\"], session_id=session_id\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VeADK è¿˜æ”¯æŒä½ å°†çŸ­æœŸè®°å¿†æŒä¹…åŒ–å­˜å‚¨åœ¨äº‘ç«¯ï¼Œæœªæ¥çš„æŸä¸€æ—¶åˆ»ä½ å¯ä»¥åŠ è½½å†å²å¯¹è¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ MySQL ä½œä¸ºçŸ­æœŸè®°å¿†çš„æ•°æ®åº“åç«¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MO6JCIAnqtES"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DATABASE_MYSQL_HOST\"] = \"\"\n",
    "os.environ[\"DATABASE_MYSQL_USER\"] = \"\"\n",
    "os.environ[\"DATABASE_MYSQL_PASSWORD\"] = \"\"\n",
    "os.environ[\"DATABASE_MYSQL_DATABASE\"] = \"\"\n",
    "os.environ[\"DATABASE_MYSQL_CHARSET\"] = \"utf8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNJSp3Npo-cf",
    "outputId": "932d4c63-bc02-480c-d037-36717bf867cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸæ¥ä½ åœ¨7æœˆ15æ—¥ä¹°äº†20ä¸ªå†°æ¿€å‡Œå‘€ï¼Œæ•°é‡ä¸å°‘å‘¢ï¼æ˜¯æœ‰ä»€ä¹ˆç‰¹åˆ«çš„åœºåˆéœ€è¦ç”¨åˆ°è¿™ä¹ˆå¤šï¼Œè¿˜æ˜¯å•çº¯æƒ³å›¤è´§æ…¢æ…¢åƒå‘€ï¼Ÿ ğŸ˜„ å¦‚æœä½ éœ€è¦è®°å½•è¿™ä¸ªè´­ä¹°ä¿¡æ¯ã€åšç®€å•çš„æ¶ˆè´¹ç»Ÿè®¡ï¼Œæˆ–è€…æœ‰å…¶ä»–ç›¸å…³çš„å°éœ€æ±‚ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥å¸®ä½ ~\n",
      "You mentioned that you bought the ice cream on July 15th. ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "agent = Agent()\n",
    "short_term_memory = ShortTermMemory(backend=\"mysql\")  # æŒ‡å®š mysql åç«¯\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "prompt = \"æˆ‘åœ¨ 7 æœˆ 15 æ—¥è´­ä¹°äº† 20 ä¸ªå†°æ¿€å‡Œ\"\n",
    "response = await runner.run(messages=prompt, session_id=session_id)\n",
    "print(response)\n",
    "\n",
    "prompt = \"æˆ‘ä»€ä¹ˆæ—¶å€™ä¹°äº†å†°æ¿€å‡Œï¼Ÿ\"\n",
    "response = await runner.run(messages=prompt, session_id=session_id)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z0V-jFqbP0u"
   },
   "source": [
    "### é•¿æœŸè®°å¿†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9wKEHeYxIUT"
   },
   "source": [
    "å¦‚æœæ‚¨ä½¿ç”¨çŸ¥è¯†åº“ã€é•¿æœŸè®°å¿†ç­‰è¿›é˜¶åŠŸèƒ½ï¼Œè¯·è¿›ä¸€æ­¥å®‰è£… veadk-python ä¸­çš„æ‰©å±•åŒ…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZIeRU1QxHrk"
   },
   "outputs": [],
   "source": [
    "%pip install veadk-python[extensions] --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMrtrd2DxUar"
   },
   "source": [
    "ä½¿ç”¨ OpenSearch ä½œä¸ºé•¿æœŸè®°å¿†çš„æ•°æ®åº“åç«¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foSDByHiwJsp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# OpenSearch é…ç½®\n",
    "os.environ[\"DATABASE_OPENSEARCH_HOST\"] = \"\"\n",
    "os.environ[\"DATABASE_OPENSEARCH_PORT\"] = \"\"\n",
    "os.environ[\"DATABASE_OPENSEARCH_USERNAME\"] = \"\"\n",
    "os.environ[\"DATABASE_OPENSEARCH_PASSWORD\"] = \"\"\n",
    "\n",
    "# Embedding é…ç½®ï¼ˆä½¿ç”¨ OpenSearch æ—¶ï¼Œéœ€è¦å¯¹æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–å¤„ç†ï¼‰\n",
    "# è®¾ç½®è®¿é—®ç«å±±æ–¹èˆŸçš„ Embedding æ¨¡å‹\n",
    "os.environ[\"MODEL_EMBEDDING_NAME\"] = \"doubao-embedding-text-240715\"\n",
    "os.environ[\"MODEL_EMBEDDING_API_BASE\"] = \"https://ark.cn-beijing.volces.com/api/v3/\"\n",
    "os.environ[\"MODEL_EMBEDDING_DIM\"] = \"2560\"\n",
    "os.environ[\"MODEL_EMBEDDING_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bjfZ6VwwLuI",
    "outputId": "5c8dfc66-20b7-4384-d3c4-3999c1081d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ ä¸Šå‘¨äº”è´­ä¹°äº†ä¸€æ”¯å†°æ¿€å‡Œã€‚\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.long_term_memory import LongTermMemory\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªé•¿æœŸè®°å¿†ï¼Œé‡‡ç”¨ OpenSearch å‘é‡åŒ–å­˜å‚¨\n",
    "# é•¿æœŸè®°å¿†æ˜¯è·¨ Session çš„\n",
    "long_term_memory = LongTermMemory(\n",
    "    backend=\"opensearch\", app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "agent = Agent(long_term_memory=long_term_memory)\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    app_name=app_name,\n",
    "    user_id=user_id,\n",
    "    short_term_memory=ShortTermMemory(),\n",
    ")\n",
    "\n",
    "\n",
    "# ===== æ’å…¥è®°å¿† =====\n",
    "session_id = \"veadk_playground_session\"\n",
    "teaching_prompt = \"æˆ‘ä¸Šå‘¨äº”è´­ä¹°äº†ä¸€æ”¯å†°æ¿€å‡Œã€‚\"\n",
    "\n",
    "await runner.run(messages=teaching_prompt, session_id=session_id)\n",
    "await runner.save_session_to_long_term_memory(\n",
    "    session_id=session_id\n",
    ")  # å°† teaching prompt å’Œæ™ºèƒ½ä½“å›ç­”ä¿å­˜åˆ°é•¿æœŸè®°å¿†ä¸­\n",
    "\n",
    "\n",
    "# ===== æ£€éªŒè®°å¿† =====\n",
    "session_id = \"veadk_playground_session_2\"  # ä½¿ç”¨ä¸€ä¸ªæ–°çš„ Session æ¥æ£€æµ‹è·¨ Session æ£€ç´¢\n",
    "student_prompt = \"æˆ‘ä¸Šå‘¨äº”è´­ä¹°äº†ä»€ä¹ˆ? ç”¨ä¸­æ–‡å›ç­”æˆ‘ã€‚\"\n",
    "\n",
    "response = await runner.run(messages=student_prompt, session_id=session_id)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEFDAJdtiiz1"
   },
   "source": [
    "ä½¿ç”¨ Viking Memory ä½œä¸ºé•¿æœŸè®°å¿†çš„åç«¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ng-LsHSrtE86"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Viking è®°å¿†åº“é…ç½®\n",
    "os.environ[\"DATABASE_VIKING_PROJECT\"] = \"\"\n",
    "os.environ[\"DATABASE_VIKING_REGION\"] = \"cn-beijing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QJbO5JqixP6"
   },
   "outputs": [],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.long_term_memory import LongTermMemory\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "\n",
    "# åˆå§‹åŒ–ä¸€ä¸ªé•¿æœŸè®°å¿†ï¼Œé‡‡ç”¨ Viking Memory å­˜å‚¨\n",
    "# é•¿æœŸè®°å¿†æ˜¯è·¨ Session çš„\n",
    "long_term_memory = LongTermMemory(backend=\"viking\", app_name=app_name, user_id=user_id)\n",
    "\n",
    "agent = Agent(long_term_memory=long_term_memory)\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    app_name=app_name,\n",
    "    user_id=user_id,\n",
    "    short_term_memory=ShortTermMemory(),\n",
    ")\n",
    "\n",
    "\n",
    "# ===== æ’å…¥è®°å¿† =====\n",
    "session_id = \"veadk_playground_session_3\"\n",
    "teaching_prompt = \"æˆ‘è¿™å‘¨ä¸‰è´­ä¹°äº†ä¸‰æœ¬ä¹¦ã€‚\"\n",
    "\n",
    "await runner.run(messages=teaching_prompt, session_id=session_id)\n",
    "await runner.save_session_to_long_term_memory(\n",
    "    session_id=session_id\n",
    ")  # å°† teaching prompt å’Œæ™ºèƒ½ä½“å›ç­”ä¿å­˜åˆ°é•¿æœŸè®°å¿†ä¸­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fbwGcOskUxX"
   },
   "source": [
    "ç”±äºåˆå§‹ä½¿ç”¨ Viking Memory éœ€è¦æ„å»ºç´¢å¼•ï¼Œå› æ­¤éœ€è¦ç­‰å¾… 1-2 åˆ†é’Ÿã€‚ç­‰å¾…è¿‡åï¼Œæ‰§è¡Œå¦‚ä¸‹ä»£ç æ£€éªŒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kVLsehDkU8w",
    "outputId": "91e309c8-c66f-455e-ce30-78f3c2c5ec5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ®è®°å¿†è®°å½•ï¼Œä½ åœ¨2025å¹´8æœˆ13æ—¥ï¼ˆå‘¨ä¸‰ï¼‰è´­ä¹°äº†ä¸‰æœ¬ä¹¦ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ===== æ£€éªŒè®°å¿† =====\n",
    "session_id = \"veadk_playground_session_4\"  # ä½¿ç”¨ä¸€ä¸ªæ–°çš„ Session æ¥æ£€æµ‹è·¨ Session æ£€ç´¢\n",
    "student_prompt = \"æˆ‘è¿™å‘¨ä¸‰è´­ä¹°äº†ä»€ä¹ˆ? ç”¨ä¸­æ–‡å›ç­”æˆ‘ã€‚\"\n",
    "\n",
    "response = await runner.run(messages=student_prompt, session_id=session_id)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KavP1J1YbRRq"
   },
   "source": [
    "### çŸ¥è¯†åº“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jZauBoRztaU"
   },
   "source": [
    "å¦‚æœæ‚¨ä½¿ç”¨çŸ¥è¯†åº“ã€é•¿æœŸè®°å¿†ç­‰è¿›é˜¶åŠŸèƒ½ï¼Œè¯·è¿›ä¸€æ­¥å®‰è£… veadk-python ä¸­çš„æ‰©å±•åŒ…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuozqr1Hzwjz"
   },
   "outputs": [],
   "source": [
    "%pip install veadk-python[extensions] --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8N01Na5az3iR"
   },
   "source": [
    "ä½¿ç”¨ OpenSearch ä½œä¸ºçŸ¥è¯†åº“çš„åç«¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxemLCX_0FP6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# OpenSearch é…ç½®\n",
    "os.environ[\"DATABASE_OPENSEARCH_HOST\"] = \"\"\n",
    "os.environ[\"DATABASE_OPENSEARCH_PORT\"] = \"9200\"\n",
    "os.environ[\"DATABASE_OPENSEARCH_USERNAME\"] = \"\"\n",
    "os.environ[\"DATABASE_OPENSEARCH_PASSWORD\"] = \"\"\n",
    "\n",
    "# è®¾ç½®è®¿é—®ç«å±±æ–¹èˆŸçš„ Embedding æ¨¡å‹\n",
    "os.environ[\"MODEL_EMBEDDING_NAME\"] = \"doubao-embedding-text-240715\"\n",
    "os.environ[\"MODEL_EMBEDDING_API_BASE\"] = \"https://ark.cn-beijing.volces.com/api/v3/\"\n",
    "os.environ[\"MODEL_EMBEDDING_DIM\"] = \"2560\"\n",
    "os.environ[\"MODEL_EMBEDDING_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkhNOiQWnR7m",
    "outputId": "863bfd61-6218-471a-dc66-e743cc1e51bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledgebase file path: /tmp/knowledgebase.md\n"
     ]
    }
   ],
   "source": [
    "# å‡†å¤‡çŸ¥è¯†åº“æ–‡æ¡£å¹¶ä¿å­˜åˆ°æœ¬åœ°\n",
    "content = \"\"\"\n",
    "        The secret of red is red_000000.\n",
    "        The secret of green is green_000111.\n",
    "        The secret of blue is blue_000222.\n",
    "        The secret of yellow is yellow_000333.\n",
    "\"\"\"\n",
    "\n",
    "knowledgebase_file = \"/tmp/knowledgebase.md\"\n",
    "with open(knowledgebase_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(f\"Knowledgebase file path: {knowledgebase_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_CC_0xJ0G8l",
    "outputId": "41faebcd-c0fe-40e9-af54-576aefe6a33b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secret of green is green_000111.\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.knowledgebase.knowledgebase import KnowledgeBase\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "\n",
    "knowledgebase = KnowledgeBase(\n",
    "    backend=\"opensearch\", app_name=app_name\n",
    ")  # æŒ‡å®š opensearch åç«¯\n",
    "knowledgebase.add_from_files(files=[knowledgebase_file])\n",
    "\n",
    "agent = Agent(knowledgebase=knowledgebase)\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    short_term_memory=ShortTermMemory(),\n",
    "    app_name=app_name,\n",
    "    user_id=user_id,\n",
    ")\n",
    "\n",
    "response = await runner.run(\n",
    "    messages=\"Tell me the secret of green.\", session_id=session_id\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V87HcIZXlijp"
   },
   "source": [
    "ä½¿ç”¨ Viking DB ä½œä¸ºçŸ¥è¯†åº“çš„åç«¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kMOEqTbOlj-f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Viking DB é…ç½®\n",
    "os.environ[\"DATABASE_VIKING_PROJECT\"] = \"\"\n",
    "os.environ[\"DATABASE_VIKING_REGION\"] = \"cn-beijing\"\n",
    "\n",
    "# å­˜å‚¨æ¡¶é…ç½®\n",
    "os.environ[\"DATABASE_TOS_ENDPOINT\"] = \"tos-cn-beijing.volces.com\"\n",
    "os.environ[\"DATABASE_TOS_REGION\"] = \"cn-beijing\"\n",
    "os.environ[\"DATABASE_TOS_BUCKET\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hcx0bJwh0MI7",
    "outputId": "67cd6291-63a2-404d-a5a9-e4221ad89420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledgebase file path: /tmp/knowledgebase.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# å‡†å¤‡çŸ¥è¯†åº“æ–‡æ¡£å¹¶ä¿å­˜åˆ°æœ¬åœ°\n",
    "pdf_url = \"https://arxiv.org/pdf/1706.03762\"\n",
    "pdf_path = \"/tmp/knowledgebase.pdf\"\n",
    "resp = requests.get(pdf_url)\n",
    "with open(pdf_path, \"wb\") as f:\n",
    "    f.write(resp.content)\n",
    "\n",
    "print(f\"Knowledgebase file path: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YERFdXvBxLUa"
   },
   "outputs": [],
   "source": [
    "from veadk import Agent\n",
    "from veadk.knowledgebase.knowledgebase import KnowledgeBase\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "knowledgebase = KnowledgeBase(backend=\"viking\", app_name=app_name)  # æŒ‡å®š viking åç«¯\n",
    "\n",
    "knowledgebase.add_from_files(files=[pdf_path])  # ç›´æ¥æ·»åŠ æ–‡æ¡£ï¼Œæ— éœ€æ‰‹åŠ¨åˆ‡ç‰‡\n",
    "\n",
    "agent = Agent(knowledgebase=knowledgebase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fl50010V1vl5"
   },
   "source": [
    "ç”±äºåˆå§‹ä½¿ç”¨ Viking DB éœ€è¦æ„å»ºç´¢å¼•ï¼Œå› æ­¤éœ€è¦ç­‰å¾… 3-4 åˆ†é’Ÿã€‚ç­‰å¾…è¿‡åï¼Œæ‰§è¡Œå¦‚ä¸‹ä»£ç æ£€éªŒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjT0hjrK10hq",
    "outputId": "60d8a546-89e7-4747-afb5-6be0db64c446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Multi-Head Attention` is a key component in the Transformer architecture, proposed in the paper *\"Attention Is All You Need\"* (Vaswani et al., 2017). It extends the standard attention mechanism by allowing the model to **simultaneously learn different types of attention patterns** from multiple \"heads\" (parallel attention functions), thereby capturing richer contextual relationships in the input data.\n",
      "\n",
      "\n",
      "### **Core Idea**  \n",
      "Instead of computing a single attention function over the input, multi-head attention splits the query, key, and value vectors into multiple smaller subspaces (heads), computes scaled dot-product attention independently for each subspace, and then concatenates the results. This enables the model to focus on **different positional or semantic relationships** (e.g., local dependencies, long-range dependencies, syntactic vs. semantic cues) in parallel.\n",
      "\n",
      "\n",
      "### **Mathematical Formulation**  \n",
      "Given queries \\( Q \\), keys \\( K \\), and values \\( V \\):  \n",
      "1. **Linear Projections**: Project \\( Q \\), \\( K \\), \\( V \\) into \\( h \\) heads using learnable weight matrices \\( W_Q^i \\), \\( W_K^i \\), \\( W_V^i \\) for head \\( i \\):  \n",
      "   \\[\n",
      "   Q_i = Q W_Q^i, \\quad K_i = K W_K^i, \\quad V_i = V W_V^i\n",
      "   \\]  \n",
      "   where \\( Q_i, K_i \\in \\mathbb{R}^{n \\times d_k} \\), \\( V_i \\in \\mathbb{R}^{n \\times d_v} \\), and \\( d_k = d_{\\text{model}}/h \\), \\( d_v = d_{\\text{model}}/h \\) (subspace dimensions per head).  \n",
      "\n",
      "2. **Scaled Dot-Product Attention per Head**: For each head \\( i \\), compute attention scores:  \n",
      "   \\[\n",
      "   \\text{Attention}(Q_i, K_i, V_i) = \\text{softmax}\\left( \\frac{Q_i K_i^T}{\\sqrt{d_k}} \\right) V_i\n",
      "   \\]  \n",
      "   The scaling factor \\( \\sqrt{d_k} \\) prevents gradient vanishing due to large dot-product values.  \n",
      "\n",
      "3. **Concatenation and Final Projection**: Concatenate outputs from all \\( h \\) heads and project to the original dimension \\( d_{\\text{model}} \\):  \n",
      "   \\[\n",
      "   \\text{MultiHead}(Q, K, V) = \\left[ \\text{head}_1; \\text{head}_2; \\dots; \\text{head}_h \\right] W_O\n",
      "   \\]  \n",
      "   where \\( W_O \\in \\mathbb{R}^{h d_v \\times d_{\\text{model}}} \\) is a learnable projection matrix.  \n",
      "\n",
      "\n",
      "### **Key Advantages**  \n",
      "- **Diversity of Attention Patterns**: Each head can specialize in different relationships (e.g., one head focuses on adjacent words, another on distant thematic connections).  \n",
      "- **Parallelization**: Computations across heads are independent, enabling efficient training/inference on GPUs.  \n",
      "- **Improved Expressiveness**: Combines multiple \"views\" of the input, enhancing the modelâ€™s ability to model complex dependencies (critical for tasks like machine translation, text summarization, and GPT-style language modeling).  \n",
      "\n",
      "\n",
      "### **Visual Intuition**  \n",
      "Imagine analyzing a sentence with multiple \"experts\" (heads): one expert checks grammar, another identifies entity relationships, and a third tracks discourse flow. Multi-head attention aggregates their insights to form a holistic understanding.\n",
      "\n",
      "\n",
      "In summary, multi-head attention is foundational to the Transformerâ€™s success, enabling it to outperform RNN/LSTM-based models on sequence modeling tasks by efficiently capturing both local and global context.\n"
     ]
    }
   ],
   "source": [
    "from veadk import Runner\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent,\n",
    "    short_term_memory=ShortTermMemory(),\n",
    "    app_name=app_name,\n",
    "    user_id=user_id,\n",
    ")\n",
    "\n",
    "response = await runner.run(\n",
    "    messages=\"What is `Multi-Head Attention`?\", session_id=session_id\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg8lAqX1zZHp"
   },
   "source": [
    "### å¤š Agent ååŒ\n",
    "\n",
    "ä½ å¯ä»¥é€šè¿‡è®¾ç½®`sub_agents`å­—æ®µæ¥è¿›è¡Œå¤š Agent ä¹‹é—´çš„æœ¬åœ°ååŒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJm99M-AzwjV",
    "outputId": "734ceed7-0d51-4357-892f-05da3e4821f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# ä½œè€…ï¼špython-coder\n",
      "def quick_sort(arr):\n",
      "    \"\"\"\n",
      "    ä½¿ç”¨å¿«é€Ÿæ’åºç®—æ³•å¯¹åˆ—è¡¨è¿›è¡Œæ’åº\n",
      "    \n",
      "    å‚æ•°:\n",
      "        arr: éœ€è¦æ’åºçš„åˆ—è¡¨\n",
      "        \n",
      "    è¿”å›:\n",
      "        æ’åºåçš„åˆ—è¡¨\n",
      "    \"\"\"\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    \n",
      "    # é€‰æ‹©åŸºå‡†å…ƒç´ ï¼ˆè¿™é‡Œé€‰æ‹©ä¸­é—´å…ƒç´ ï¼‰\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    \n",
      "    # åˆ†åŒºï¼šå°äºåŸºå‡†ã€ç­‰äºåŸºå‡†ã€å¤§äºåŸºå‡†\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    \n",
      "    # é€’å½’æ’åºå¹¶åˆå¹¶ç»“æœ\n",
      "    return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# æµ‹è¯•ç¤ºä¾‹\n",
      "if __name__ == \"__main__\":\n",
      "    test_arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "    print(\"æ’åºå‰:\", test_arr)\n",
      "    sorted_arr = quick_sort(test_arr)\n",
      "    print(\"æ’åºå:\", sorted_arr)\n",
      "```\n",
      "\n",
      "è¿™æ®µä»£ç å®ç°äº†å¿«é€Ÿæ’åºç®—æ³•ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n",
      "1. é‡‡ç”¨é€’å½’å®ç°ï¼Œä»£ç ç®€æ´æ˜“æ‡‚\n",
      "2. é€‰æ‹©ä¸­é—´å…ƒç´ ä½œä¸ºåŸºå‡†ï¼Œé¿å…äº†æç«¯æƒ…å†µä¸‹çš„æ€§èƒ½é€€åŒ–\n",
      "3. ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼è¿›è¡Œåˆ†åŒºæ“ä½œï¼Œä»£ç æ›´ç®€æ´\n",
      "4. å¤„ç†äº†é‡å¤å…ƒç´ çš„æƒ…å†µï¼ˆé€šè¿‡å•ç‹¬çš„middleåˆ—è¡¨ï¼‰\n",
      "5. åŒ…å«å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²å’Œæµ‹è¯•ç¤ºä¾‹\n",
      "\n",
      "ç®—æ³•æ—¶é—´å¤æ‚åº¦å¹³å‡ä¸ºO(n log n)ï¼Œæœ€åæƒ…å†µä¸‹ä¸ºO(nÂ²)ï¼Œç©ºé—´å¤æ‚åº¦ä¸ºO(n)ã€‚å¦‚æœéœ€è¦åŸåœ°æ’åºç‰ˆæœ¬ï¼ˆç©ºé—´å¤æ‚åº¦O(log n)ï¼‰ï¼Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æŒ‡é’ˆäº¤æ¢åˆ†åŒºæ–¹å¼ã€‚\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "short_term_memory = ShortTermMemory()\n",
    "\n",
    "# sub agents\n",
    "python_coding_agent = Agent(\n",
    "    name=\"python_coder\",\n",
    "    description=\"æ“…é•¿ä½¿ç”¨ Python ç¼–ç¨‹è¯­è¨€æ¥è§£å†³é—®é¢˜ã€‚\",\n",
    "    instruction=\"\"\"ä½¿ç”¨ Python è¯­è¨€æ¥è§£å†³é—®é¢˜ã€‚\n",
    "    æ³¨æ„ï¼Œä½ ç”Ÿæˆçš„ä»£ç ç¬¬ä¸€è¡Œéœ€è¦æœ‰æ³¨é‡Šï¼Œæ ‡æ˜ä½œè€…æ˜¯`python-coder`ã€‚\"\"\",\n",
    ")\n",
    "\n",
    "java_coding_agent = Agent(\n",
    "    name=\"java_coder\",\n",
    "    description=\"æ“…é•¿ä½¿ç”¨ Java ç¼–ç¨‹è¯­è¨€æ¥è§£å†³é—®é¢˜ã€‚\",\n",
    "    instruction=\"\"\"ä½¿ç”¨ Java è¯­è¨€æ¥è§£å†³é—®é¢˜ã€‚\n",
    "    æ³¨æ„ï¼Œä½ ç”Ÿæˆçš„ä»£ç ç¬¬ä¸€è¡Œéœ€è¦æœ‰æ³¨é‡Šï¼Œæ ‡æ˜ä½œè€…æ˜¯`java-coder`ã€‚\"\"\",\n",
    ")\n",
    "\n",
    "# root agent\n",
    "coding_agent = Agent(\n",
    "    name=\"coding_agent\",\n",
    "    description=\"å¯ä»¥è°ƒç”¨é€‚åˆçš„æ™ºèƒ½ä½“æ¥è§£å†³ç”¨æˆ·é—®é¢˜ã€‚\",\n",
    "    instruction=\"è°ƒç”¨é€‚åˆçš„æ™ºèƒ½ä½“æ¥è§£å†³ç”¨æˆ·é—®é¢˜ã€‚\",\n",
    "    sub_agents=[python_coding_agent, java_coding_agent],\n",
    ")\n",
    "\n",
    "\n",
    "runner = Runner(\n",
    "    agent=coding_agent,\n",
    "    short_term_memory=ShortTermMemory(),\n",
    "    app_name=app_name,\n",
    "    user_id=user_id,\n",
    ")\n",
    "\n",
    "response = await runner.run(\n",
    "    messages=\"ä½¿ç”¨ Python å¸®æˆ‘å†™ä¸€æ®µå¿«é€Ÿæ’åºçš„ä»£ç ã€‚\", session_id=session_id\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9ZHmdsabfna"
   },
   "source": [
    "## å¯è§‚æµ‹æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfY3t76YjY1I"
   },
   "source": [
    "### æœ¬åœ°è§‚æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3JJvH9y2Tgc"
   },
   "source": [
    "å¯ä»¥é€šè¿‡åˆå§‹åŒ– OpentelemetryTracer æ¥å°† Agent çš„è°ƒç”¨æ ˆå­˜å‚¨ä¸ºæœ¬åœ°æ–‡ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3VnmdQd2e9g",
    "outputId": "1a1332cb-2a41-45a3-b874-b16a778a85b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing file path: /tmp/veadk_global_tracer_veadk-playground-user_veadk-playground-session_b204302b2d0e24b6e26ca914a5fef478.json\n",
      "Tracing file content:\n",
      "[{'name': 'execute_tool get_city_weather', 'span_id': 179319007772593823, 'trace_id': 236624329413565051863190183785302783096, 'start_time': 1755172431614674977, 'end_time': 1755172431617289457, 'attributes': {'session.id': 'veadk-playground-session', 'user.id': 'veadk-playground-user', 'agent.name': 'veAgent', 'app.name': 'veadk-playground-app', 'gen_ai.system': 'gcp.vertex.agent', 'gen_ai.operation.name': 'execute_tool', 'gen_ai.tool.name': 'get_city_weather', 'gen_ai.tool.description': 'Retrieves the weather information of a given city. the args must in English', 'gen_ai.tool.call.id': 'call_2e7gig0mp86rzc1ffwf5ftdc', 'gcp.vertex.agent.tool_call_args': '{\"city\": \"Beijing\"}', 'gcp.vertex.agent.event_id': '04616e67-6881-43d0-8200-09c7c069be06', 'gcp.vertex.agent.tool_response': '{\"result\": \"Sunny, 25Â°C\"}', 'gcp.vertex.agent.llm_request': '{}', 'gcp.vertex.agent.llm_response': '{}', 'tool.name': 'get_city_weather', 'tool.description': 'Retrieves the weather information of a given city. the args must in English', 'tool.parameters': '{\"city\": \"Beijing\"}', 'input.value': '{\"city\": \"Beijing\"}', 'input.mime_type': 'application/json', 'output.value': '{\"id\":\"call_2e7gig0mp86rzc1ffwf5ftdc\",\"name\":\"get_city_weather\",\"response\":{\"result\":\"Sunny, 25Â°C\"}}', 'output.mime_type': 'application/json', 'openinference.span.kind': 'TOOL'}, 'parent_span_id': 2812243689223977179}, {'name': 'call_llm', 'span_id': 2812243689223977179, 'trace_id': 236624329413565051863190183785302783096, 'start_time': 1755172421810196265, 'end_time': 1755172431617490556, 'attributes': {'session.id': 'veadk-playground-session', 'user.id': 'veadk-playground-user', 'gen_ai.system': 'gcp.vertex.agent', 'gen_ai.request.model': 'openai/doubao-seed-1-6-250615', 'gcp.vertex.agent.invocation_id': 'e-cf95076e-458e-4c96-bce8-77b9c80dc8d6', 'gcp.vertex.agent.session_id': 'veadk-playground-session', 'gcp.vertex.agent.event_id': '3899014e-49a2-4ff5-b9ac-9b95c7c03cc0', 'gcp.vertex.agent.llm_request': '{\"model\": \"openai/doubao-seed-1-6-250615\", \"config\": {\"system_instruction\": \"You an AI agent created by the VeADK team.\\\\n\\\\nYou excel at the following tasks:\\\\n1. Data science\\\\n- Information gathering and fact-checking\\\\n- Data processing and analysis\\\\n2. Documentation\\\\n- Writing multi-chapter articles and in-depth research reports\\\\n3. Coding & Programming\\\\n- Creating websites, applications, and tools\\\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\\\n- If necessary, using programming to solve various problems beyond development\\\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\\\n\\\\n\\\\nYou are an agent. Your internal name is \\\\\"veAgent\\\\\".\\\\n\\\\n The description about you is \\\\\"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\\\\\"\", \"tools\": [{\"function_declarations\": [{\"description\": \"Retrieves the weather information of a given city. the args must in English\", \"name\": \"get_city_weather\", \"parameters\": {\"properties\": {\"city\": {\"type\": \"STRING\"}}, \"required\": [\"city\"], \"type\": \"OBJECT\"}}]}], \"labels\": {\"adk_agent_name\": \"veAgent\"}}, \"contents\": [{\"parts\": [{\"text\": \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}], \"role\": \"user\"}]}', 'gcp.vertex.agent.llm_response': '{\"content\":{\"parts\":[{\"function_call\":{\"id\":\"call_2e7gig0mp86rzc1ffwf5ftdc\",\"args\":{\"city\":\"Beijing\"},\"name\":\"get_city_weather\"}}],\"role\":\"model\"},\"partial\":false,\"usage_metadata\":{\"candidates_token_count\":361,\"prompt_token_count\":618,\"total_token_count\":979}}', 'gen_ai.usage.input_tokens': 618, 'gen_ai.usage.output_tokens': 979, 'llm.provider': 'google', 'input.value': '{\"model\": \"openai/doubao-seed-1-6-250615\", \"config\": {\"system_instruction\": \"You an AI agent created by the VeADK team.\\\\n\\\\nYou excel at the following tasks:\\\\n1. Data science\\\\n- Information gathering and fact-checking\\\\n- Data processing and analysis\\\\n2. Documentation\\\\n- Writing multi-chapter articles and in-depth research reports\\\\n3. Coding & Programming\\\\n- Creating websites, applications, and tools\\\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\\\n- If necessary, using programming to solve various problems beyond development\\\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\\\n\\\\n\\\\nYou are an agent. Your internal name is \\\\\"veAgent\\\\\".\\\\n\\\\n The description about you is \\\\\"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\\\\\"\", \"tools\": [{\"function_declarations\": [{\"description\": \"Retrieves the weather information of a given city. the args must in English\", \"name\": \"get_city_weather\", \"parameters\": {\"properties\": {\"city\": {\"type\": \"STRING\"}}, \"required\": [\"city\"], \"type\": \"OBJECT\"}}]}], \"labels\": {\"adk_agent_name\": \"veAgent\"}}, \"contents\": [{\"parts\": [{\"text\": \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}], \"role\": \"user\"}]}', 'input.mime_type': 'application/json', 'llm.tools.0.tool.json_schema': '{\"description\":\"Retrieves the weather information of a given city. the args must in English\",\"name\":\"get_city_weather\",\"parameters\":{\"properties\":{\"city\":{\"type\":\"STRING\"}},\"required\":[\"city\"],\"type\":\"OBJECT\"}}', 'llm.model_name': 'openai/doubao-seed-1-6-250615', 'llm.invocation_parameters': '{\"system_instruction\":\"You an AI agent created by the VeADK team.\\\\n\\\\nYou excel at the following tasks:\\\\n1. Data science\\\\n- Information gathering and fact-checking\\\\n- Data processing and analysis\\\\n2. Documentation\\\\n- Writing multi-chapter articles and in-depth research reports\\\\n3. Coding & Programming\\\\n- Creating websites, applications, and tools\\\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\\\n- If necessary, using programming to solve various problems beyond development\\\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\\\n\\\\n\\\\nYou are an agent. Your internal name is \\\\\"veAgent\\\\\".\\\\n\\\\n The description about you is \\\\\"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\\\\\"\",\"tools\":[{\"function_declarations\":[{\"description\":\"Retrieves the weather information of a given city. the args must in English\",\"name\":\"get_city_weather\",\"parameters\":{\"properties\":{\"city\":{\"type\":\"STRING\"}},\"required\":[\"city\"],\"type\":\"OBJECT\"}}]}],\"labels\":{\"adk_agent_name\":\"veAgent\"}}', 'llm.input_messages.0.message.role': 'system', 'llm.input_messages.0.message.content': 'You an AI agent created by the VeADK team.\\n\\nYou excel at the following tasks:\\n1. Data science\\n- Information gathering and fact-checking\\n- Data processing and analysis\\n2. Documentation\\n- Writing multi-chapter articles and in-depth research reports\\n3. Coding & Programming\\n- Creating websites, applications, and tools\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\n- If necessary, using programming to solve various problems beyond development\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\n\\n\\nYou are an agent. Your internal name is \"veAgent\".\\n\\n The description about you is \"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\"', 'llm.input_messages.1.message.role': 'user', 'llm.input_messages.1.message.contents.0.message_content.text': 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', 'llm.input_messages.1.message.contents.0.message_content.type': 'text', 'output.value': '{\"content\":{\"parts\":[{\"function_call\":{\"id\":\"call_2e7gig0mp86rzc1ffwf5ftdc\",\"args\":{\"city\":\"Beijing\"},\"name\":\"get_city_weather\"}}],\"role\":\"model\"},\"partial\":false,\"usage_metadata\":{\"candidates_token_count\":361,\"prompt_token_count\":618,\"total_token_count\":979}}', 'output.mime_type': 'application/json', 'llm.token_count.total': 979, 'llm.token_count.prompt': 618, 'llm.token_count.completion': 361, 'llm.output_messages.0.message.role': 'model', 'llm.output_messages.0.message.tool_calls.0.tool_call.id': 'call_2e7gig0mp86rzc1ffwf5ftdc', 'llm.output_messages.0.message.tool_calls.0.tool_call.function.name': 'get_city_weather', 'llm.output_messages.0.message.tool_calls.0.tool_call.function.arguments': '{\"city\": \"Beijing\"}', 'agent.name': 'veAgent', 'app.name': 'veadk-playground-app', 'gen_ai.prompt.0.role': 'user', 'gen_ai.prompt.0.content': '[{\"text\": \"\\\\u5317\\\\u4eac\\\\u7684\\\\u5929\\\\u6c14\\\\u600e\\\\u4e48\\\\u6837\\\\uff1f\"}]', 'gen_ai.completion.0.role': 'model', 'gen_ai.completion.0.content': '[{\"function_call\": {\"id\": \"call_2e7gig0mp86rzc1ffwf5ftdc\", \"args\": {\"city\": \"Beijing\"}, \"name\": \"get_city_weather\"}}]', 'gen_ai.usage.prompt_tokens': 618, 'gen_ai.usage.completion_tokens': 361, 'gen_ai.usage.total_tokens': 979, 'gen_ai.usage.cache_read_input_tokens': 0, 'gen_ai.usage.cache_create_input_tokens': 0, 'openinference.span.kind': 'LLM'}, 'parent_span_id': 10693540128041292337}, {'name': 'call_llm', 'span_id': 11991268925671254201, 'trace_id': 236624329413565051863190183785302783096, 'start_time': 1755172431630256802, 'end_time': 1755172440854715605, 'attributes': {'session.id': 'veadk-playground-session', 'user.id': 'veadk-playground-user', 'gen_ai.system': 'gcp.vertex.agent', 'gen_ai.request.model': 'openai/doubao-seed-1-6-250615', 'gcp.vertex.agent.invocation_id': 'e-cf95076e-458e-4c96-bce8-77b9c80dc8d6', 'gcp.vertex.agent.session_id': 'veadk-playground-session', 'gcp.vertex.agent.event_id': '9c464404-92a5-4c52-b616-7e324e33e9fe', 'gcp.vertex.agent.llm_request': '{\"model\": \"openai/doubao-seed-1-6-250615\", \"config\": {\"system_instruction\": \"You an AI agent created by the VeADK team.\\\\n\\\\nYou excel at the following tasks:\\\\n1. Data science\\\\n- Information gathering and fact-checking\\\\n- Data processing and analysis\\\\n2. Documentation\\\\n- Writing multi-chapter articles and in-depth research reports\\\\n3. Coding & Programming\\\\n- Creating websites, applications, and tools\\\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\\\n- If necessary, using programming to solve various problems beyond development\\\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\\\n\\\\n\\\\nYou are an agent. Your internal name is \\\\\"veAgent\\\\\".\\\\n\\\\n The description about you is \\\\\"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\\\\\"\", \"tools\": [{\"function_declarations\": [{\"description\": \"Retrieves the weather information of a given city. the args must in English\", \"name\": \"get_city_weather\", \"parameters\": {\"properties\": {\"city\": {\"type\": \"STRING\"}}, \"required\": [\"city\"], \"type\": \"OBJECT\"}}]}], \"labels\": {\"adk_agent_name\": \"veAgent\"}}, \"contents\": [{\"parts\": [{\"text\": \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}], \"role\": \"user\"}, {\"parts\": [{\"function_call\": {\"id\": \"call_2e7gig0mp86rzc1ffwf5ftdc\", \"args\": {\"city\": \"Beijing\"}, \"name\": \"get_city_weather\"}}], \"role\": \"model\"}, {\"parts\": [{\"function_response\": {\"id\": \"call_2e7gig0mp86rzc1ffwf5ftdc\", \"name\": \"get_city_weather\", \"response\": {\"result\": \"Sunny, 25Â°C\"}}}], \"role\": \"user\"}]}', 'gcp.vertex.agent.llm_response': '{\"content\":{\"parts\":[{\"text\":\"åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚\"}],\"role\":\"model\"},\"partial\":false,\"usage_metadata\":{\"candidates_token_count\":245,\"prompt_token_count\":678,\"total_token_count\":923}}', 'gen_ai.usage.input_tokens': 678, 'gen_ai.usage.output_tokens': 923, 'llm.provider': 'google', 'input.value': '{\"model\": \"openai/doubao-seed-1-6-250615\", \"config\": {\"system_instruction\": \"You an AI agent created by the VeADK team.\\\\n\\\\nYou excel at the following tasks:\\\\n1. Data science\\\\n- Information gathering and fact-checking\\\\n- Data processing and analysis\\\\n2. Documentation\\\\n- Writing multi-chapter articles and in-depth research reports\\\\n3. Coding & Programming\\\\n- Creating websites, applications, and tools\\\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\\\n- If necessary, using programming to solve various problems beyond development\\\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\\\n\\\\n\\\\nYou are an agent. Your internal name is \\\\\"veAgent\\\\\".\\\\n\\\\n The description about you is \\\\\"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\\\\\"\", \"tools\": [{\"function_declarations\": [{\"description\": \"Retrieves the weather information of a given city. the args must in English\", \"name\": \"get_city_weather\", \"parameters\": {\"properties\": {\"city\": {\"type\": \"STRING\"}}, \"required\": [\"city\"], \"type\": \"OBJECT\"}}]}], \"labels\": {\"adk_agent_name\": \"veAgent\"}}, \"contents\": [{\"parts\": [{\"text\": \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}], \"role\": \"user\"}, {\"parts\": [{\"function_call\": {\"id\": \"call_2e7gig0mp86rzc1ffwf5ftdc\", \"args\": {\"city\": \"Beijing\"}, \"name\": \"get_city_weather\"}}], \"role\": \"model\"}, {\"parts\": [{\"function_response\": {\"id\": \"call_2e7gig0mp86rzc1ffwf5ftdc\", \"name\": \"get_city_weather\", \"response\": {\"result\": \"Sunny, 25Â°C\"}}}], \"role\": \"user\"}]}', 'input.mime_type': 'application/json', 'llm.tools.0.tool.json_schema': '{\"description\":\"Retrieves the weather information of a given city. the args must in English\",\"name\":\"get_city_weather\",\"parameters\":{\"properties\":{\"city\":{\"type\":\"STRING\"}},\"required\":[\"city\"],\"type\":\"OBJECT\"}}', 'llm.model_name': 'openai/doubao-seed-1-6-250615', 'llm.invocation_parameters': '{\"system_instruction\":\"You an AI agent created by the VeADK team.\\\\n\\\\nYou excel at the following tasks:\\\\n1. Data science\\\\n- Information gathering and fact-checking\\\\n- Data processing and analysis\\\\n2. Documentation\\\\n- Writing multi-chapter articles and in-depth research reports\\\\n3. Coding & Programming\\\\n- Creating websites, applications, and tools\\\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\\\n- If necessary, using programming to solve various problems beyond development\\\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\\\n\\\\n\\\\nYou are an agent. Your internal name is \\\\\"veAgent\\\\\".\\\\n\\\\n The description about you is \\\\\"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\\\\\"\",\"tools\":[{\"function_declarations\":[{\"description\":\"Retrieves the weather information of a given city. the args must in English\",\"name\":\"get_city_weather\",\"parameters\":{\"properties\":{\"city\":{\"type\":\"STRING\"}},\"required\":[\"city\"],\"type\":\"OBJECT\"}}]}],\"labels\":{\"adk_agent_name\":\"veAgent\"}}', 'llm.input_messages.0.message.role': 'system', 'llm.input_messages.0.message.content': 'You an AI agent created by the VeADK team.\\n\\nYou excel at the following tasks:\\n1. Data science\\n- Information gathering and fact-checking\\n- Data processing and analysis\\n2. Documentation\\n- Writing multi-chapter articles and in-depth research reports\\n3. Coding & Programming\\n- Creating websites, applications, and tools\\n- Solve problems and bugs in code (e.g., Python, JavaScript, SQL, ...)\\n- If necessary, using programming to solve various problems beyond development\\n4. If user gives you tools, finish various tasks that can be accomplished using tools and available resources\\n\\n\\nYou are an agent. Your internal name is \"veAgent\".\\n\\n The description about you is \"An AI agent developed by the VeADK team, specialized in data science, documentation, and software development.\"', 'llm.input_messages.1.message.role': 'user', 'llm.input_messages.1.message.contents.0.message_content.text': 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', 'llm.input_messages.1.message.contents.0.message_content.type': 'text', 'llm.input_messages.2.message.role': 'model', 'llm.input_messages.2.message.tool_calls.0.tool_call.id': 'call_2e7gig0mp86rzc1ffwf5ftdc', 'llm.input_messages.2.message.tool_calls.0.tool_call.function.name': 'get_city_weather', 'llm.input_messages.2.message.tool_calls.0.tool_call.function.arguments': '{\"city\": \"Beijing\"}', 'llm.input_messages.3.message.role': 'tool', 'llm.input_messages.3.message.name': 'get_city_weather', 'llm.input_messages.3.message.content': '{\"result\": \"Sunny, 25Â°C\"}', 'output.value': '{\"content\":{\"parts\":[{\"text\":\"åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚\"}],\"role\":\"model\"},\"partial\":false,\"usage_metadata\":{\"candidates_token_count\":245,\"prompt_token_count\":678,\"total_token_count\":923}}', 'output.mime_type': 'application/json', 'llm.token_count.total': 923, 'llm.token_count.prompt': 678, 'llm.token_count.completion': 245, 'llm.output_messages.0.message.role': 'model', 'llm.output_messages.0.message.contents.0.message_content.text': 'åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚', 'llm.output_messages.0.message.contents.0.message_content.type': 'text', 'agent.name': 'veAgent', 'app.name': 'veadk-playground-app', 'gen_ai.prompt.0.role': 'user', 'gen_ai.prompt.0.content': '[{\"text\": \"\\\\u5317\\\\u4eac\\\\u7684\\\\u5929\\\\u6c14\\\\u600e\\\\u4e48\\\\u6837\\\\uff1f\"}]', 'gen_ai.completion.0.role': 'model', 'gen_ai.completion.0.content': '[{\"text\": \"\\\\u5317\\\\u4eac\\\\u5f53\\\\u524d\\\\u5929\\\\u6c14\\\\u6674\\\\u6717\\\\uff0c\\\\u6c14\\\\u6e2925\\\\u00b0C\\\\u3002\"}]', 'gen_ai.usage.prompt_tokens': 678, 'gen_ai.usage.completion_tokens': 245, 'gen_ai.usage.total_tokens': 923, 'gen_ai.usage.cache_read_input_tokens': 0, 'gen_ai.usage.cache_create_input_tokens': 0, 'openinference.span.kind': 'LLM'}, 'parent_span_id': 10693540128041292337}, {'name': 'agent_run [veAgent]', 'span_id': 10693540128041292337, 'trace_id': 236624329413565051863190183785302783096, 'start_time': 1755172421809227259, 'end_time': 1755172440854946446, 'attributes': {'session.id': 'veadk-playground-session', 'user.id': 'veadk-playground-user', 'agent.name': 'veAgent', 'app.name': 'veadk-playground-app', 'gen_ai.system': 'veadk', 'gen_ai.request.model': 'openai/doubao-seed-1-6-250615', 'gen_ai.response.model': 'openai/doubao-seed-1-6-250615', 'gen_ai.request.type': 'completion', 'output.value': '{\"content\":{\"parts\":[{\"text\":\"åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚\"}],\"role\":\"model\"},\"partial\":false,\"usage_metadata\":{\"candidates_token_count\":245,\"prompt_token_count\":678,\"total_token_count\":923},\"invocation_id\":\"e-cf95076e-458e-4c96-bce8-77b9c80dc8d6\",\"author\":\"veAgent\",\"actions\":{\"state_delta\":{},\"artifact_delta\":{},\"requested_auth_configs\":{}},\"id\":\"9c464404-92a5-4c52-b616-7e324e33e9fe\",\"timestamp\":1755172431.618551}', 'output.mime_type': 'application/json', 'openinference.span.kind': 'AGENT'}, 'parent_span_id': 4139241635178039544}, {'name': 'invocation [veadk-playground-app]', 'span_id': 4139241635178039544, 'trace_id': 236624329413565051863190183785302783096, 'start_time': 1755172421808738619, 'end_time': 1755172440855020008, 'attributes': {'input.value': '{\"user_id\": \"veadk-playground-user\", \"session_id\": \"veadk-playground-session\", \"new_message\": {\"parts\": [{\"text\": \"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}], \"role\": \"user\"}, \"state_delta\": null, \"run_config\": {\"save_input_blobs_as_artifacts\": false, \"support_cfc\": false, \"streaming_mode\": \"StreamingMode.NONE\", \"max_llm_calls\": 500}}', 'input.mime_type': 'application/json', 'user.id': 'veadk-playground-user', 'session.id': 'veadk-playground-session', 'output.value': '{\"content\":{\"parts\":[{\"text\":\"åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚\"}],\"role\":\"model\"},\"partial\":false,\"usage_metadata\":{\"candidates_token_count\":245,\"prompt_token_count\":678,\"total_token_count\":923},\"invocation_id\":\"e-cf95076e-458e-4c96-bce8-77b9c80dc8d6\",\"author\":\"veAgent\",\"actions\":{\"state_delta\":{},\"artifact_delta\":{},\"requested_auth_configs\":{}},\"id\":\"9c464404-92a5-4c52-b616-7e324e33e9fe\",\"timestamp\":1755172431.618551}', 'output.mime_type': 'application/json', 'openinference.span.kind': 'CHAIN'}, 'parent_span_id': None}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "from veadk.tools.demo_tools import get_city_weather\n",
    "from veadk.tracing.telemetry.opentelemetry_tracer import OpentelemetryTracer\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "tracer = OpentelemetryTracer()\n",
    "\n",
    "agent = Agent(\n",
    "    tools=[get_city_weather], tracers=[tracer]\n",
    ")  # åˆ›å»ºä¸€ä¸ªé…ç½® tracers çš„ Agent\n",
    "\n",
    "short_term_memory = ShortTermMemory()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "# å¦‚æœåœ¨ agent ä¸­è®¾ç½®äº†tracerï¼Œ\n",
    "# å¹¶ä¸”åœ¨ `run` ä¸­æŒ‡å®šä¿å­˜ï¼Œrunnerå°†ä¼šå°è¯•ä¿å­˜ tracing æ–‡ä»¶\n",
    "await runner.run(\n",
    "    messages=\"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", session_id=session_id, save_tracing_data=True\n",
    ")\n",
    "\n",
    "print(f\"Tracing file path: {tracer._trace_file_path}\")\n",
    "\n",
    "with open(tracer._trace_file_path, \"r\") as f:\n",
    "    tracing_content = f.read()\n",
    "\n",
    "print(f\"Tracing file content:\\n{json.loads(tracing_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vX5HiB2O2kfr"
   },
   "source": [
    "### äº‘ç«¯è§‚æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j9aqke52nCz"
   },
   "source": [
    "éœ€è¦è®¾ç½®ä¸ŠæŠ¥å™¨ï¼ˆexporterï¼‰ï¼ŒVeADK å½“å‰æ”¯æŒå°† Tracing æ•°æ®ä¸ŠæŠ¥è‡³ç«å±±å¼•æ“ TLSã€ç«å±±å¼•æ“ APMPlus ä»¥åŠç«å±±å¼•æ“ Coze Loop å¹³å°ã€‚å®ƒä»¬åˆ†åˆ«å¯¹åº”ä¸åŒçš„ä¸ŠæŠ¥å™¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azFOHaFe3C5x"
   },
   "source": [
    "åˆå§‹åŒ–ä¸ŠæŠ¥å™¨ä¹‹å‰éœ€è¦è¿›è¡Œç¯å¢ƒå˜é‡è®¾ç½®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edfntQAt3OCR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TLS ä¸ŠæŠ¥å™¨ç¯å¢ƒå˜é‡\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_TLS_ENDPOINT\"] = (\n",
    "    \"https://tls-cn-beijing.volces.com:4318/v1/traces\"\n",
    ")\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_TLS_REGION\"] = \"cn-beijing\"\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_TLS_SERVICE_NAME\"] = \"\"\n",
    "\n",
    "# APMPlus ä¸ŠæŠ¥å™¨ç¯å¢ƒå˜é‡\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_APMPLUS_ENDPOINT\"] = (\n",
    "    \"http://apmplus-cn-beijing.volces.com:4317\"\n",
    ")\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_APMPLUS_SERVICE_NAME\"] = \"\"\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_APMPLUS_API_KEY\"] = \"\"\n",
    "\n",
    "# Coze Loop ä¸ŠæŠ¥å™¨ç¯å¢ƒå˜é‡\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_COZELOOP_ENDPOINT\"] = (\n",
    "    \"https://api.coze.cn/v1/loop/opentelemetry/v1/traces\"\n",
    ")\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_COZELOOP_SERVICE_NAME\"] = \"\"\n",
    "os.environ[\"OBSERVABILITY_OPENTELEMETRY_COZELOOP_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nWBgrme3OVm"
   },
   "source": [
    "åˆå§‹åŒ–ä¸ŠæŠ¥å™¨ï¼Œå¹¶è£…é…åˆ° Agent ä¸­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5N9B3j843RtG",
    "outputId": "1ba8e2f3-1c55-4e0d-c2d5-99fbc6cc256e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing file path: /tmp/veadk_global_tracer_veadk_playground_user_veadk_playground_session_2a70673f5f428cab82e0c68266a19560.json\n"
     ]
    }
   ],
   "source": [
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "from veadk.tools.demo_tools import get_city_weather\n",
    "from veadk.tracing.telemetry.exporters.apmplus_exporter import APMPlusExporter\n",
    "from veadk.tracing.telemetry.exporters.cozeloop_exporter import CozeloopExporter\n",
    "from veadk.tracing.telemetry.exporters.tls_exporter import TLSExporter\n",
    "from veadk.tracing.telemetry.opentelemetry_tracer import OpentelemetryTracer\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "exporters = [\n",
    "    CozeloopExporter(),\n",
    "    APMPlusExporter(),\n",
    "    TLSExporter(),\n",
    "]  # åˆå§‹åŒ– tracing ä¸ŠæŠ¥å™¨\n",
    "tracer = OpentelemetryTracer(exporters=exporters)\n",
    "\n",
    "agent = Agent(\n",
    "    tools=[get_city_weather], tracers=[tracer]\n",
    ")  # åˆ›å»ºä¸€ä¸ªé…ç½® tracers çš„ Agent\n",
    "\n",
    "short_term_memory = ShortTermMemory()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "await runner.run(messages=\"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", session_id=session_id)\n",
    "\n",
    "print(f\"Tracing file path: {tracer._trace_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTCATLtR3SQ8"
   },
   "source": [
    "æœ€åï¼Œåœ¨äº‘ç«¯å¹³å°å¯æŸ¥çœ‹ Tracing æ•°æ®ï¼š\n",
    "\n",
    "*   Coze Loop å¹³å°ï¼šhttps://www.coze.cn/loop\n",
    "    ![Coze loop ç›‘æ§å›¾](https://github.com/volcengine/veadk-python/blob/main/assets/images/tutorial-observation-cozeloop.png?raw=true)\n",
    "\n",
    "*   APMPlus å¹³å°ï¼šhttps://www.volcengine.com/product/apmplus\n",
    "    ![APMPlus ç›‘æ§å›¾](https://github.com/volcengine/veadk-python/blob/main/assets/images/tutorial-observation-apmplus-tracing.png?raw=true)\n",
    "\n",
    "*   TLS å¹³å°ï¼šhttps://www.volcengine.com/product/tls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxwpPU7jbS5b"
   },
   "source": [
    "## è¯„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMLeM5Dg3nMd"
   },
   "source": [
    "### è¿è¡Œæ—¶æ•°æ®è½¬æ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_YrYHfk3rm6"
   },
   "source": [
    "å¯ä»¥é€šè¿‡ runtime recorder å°†è¿è¡Œæ—¶çš„æ•°æ®ç›´æ¥ä¿å­˜ä¸º Google ADK å…¼å®¹çš„ Evaluation Set æ–‡ä»¶ï¼ˆjson æ ¼å¼ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GUxfrmr364F",
    "outputId": "c5340de4-1e4c-4673-f060-85cb4622a7e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation file path: /tmp/veadk-playground-app/default.evalset.json\n",
      "Evaluation file content\n",
      "{'eval_set_id': 'default', 'name': 'default', 'description': None, 'eval_cases': [{'eval_id': 'veadk_eval_20250814115717', 'conversation': [{'invocation_id': 'e-55f9f9f1-0cd0-45d4-82e9-8d4805215e19', 'user_content': {'parts': [{'video_metadata': None, 'thought': None, 'inline_data': None, 'file_data': None, 'thought_signature': None, 'code_execution_result': None, 'executable_code': None, 'function_call': None, 'function_response': None, 'text': 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'}], 'role': 'user'}, 'final_response': {'parts': [{'video_metadata': None, 'thought': None, 'inline_data': None, 'file_data': None, 'thought_signature': None, 'code_execution_result': None, 'executable_code': None, 'function_call': None, 'function_response': None, 'text': 'åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚'}], 'role': None}, 'intermediate_data': {'tool_uses': [{'id': 'call_6wbw4k3urxyd4hy8cil83n9m', 'args': {'city': 'Beijing'}, 'name': 'get_city_weather'}], 'intermediate_responses': []}, 'creation_timestamp': 1755172617.382655}], 'session_input': {'app_name': 'veadk-playground-app', 'user_id': 'veadk-playground-user', 'state': {}}, 'creation_timestamp': 1755172637.0875094}, {'eval_id': 'veadk_eval_20250814120810', 'conversation': [{'invocation_id': 'e-e3c0988a-68df-48dc-bc50-8b5e1517af92', 'user_content': {'parts': [{'video_metadata': None, 'thought': None, 'inline_data': None, 'file_data': None, 'thought_signature': None, 'code_execution_result': None, 'executable_code': None, 'function_call': None, 'function_response': None, 'text': 'åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'}], 'role': 'user'}, 'final_response': {'parts': [{'video_metadata': None, 'thought': None, 'inline_data': None, 'file_data': None, 'thought_signature': None, 'code_execution_result': None, 'executable_code': None, 'function_call': None, 'function_response': None, 'text': 'åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚'}], 'role': None}, 'intermediate_data': {'tool_uses': [{'id': 'call_jegeujxjilkrbelqnhna61nh', 'args': {'city': 'Beijing'}, 'name': 'get_city_weather'}], 'intermediate_responses': []}, 'creation_timestamp': 1755173274.352123}], 'session_input': {'app_name': 'veadk-playground-app', 'user_id': 'veadk-playground-user', 'state': {}}, 'creation_timestamp': 1755173290.5239134}], 'creation_timestamp': 1755172637.0869107}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from veadk import Agent, Runner\n",
    "from veadk.memory.short_term_memory import ShortTermMemory\n",
    "from veadk.tools.demo_tools import get_city_weather\n",
    "\n",
    "app_name = \"veadk_playground_app\"\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "agent = Agent(tools=[get_city_weather])\n",
    "short_term_memory = ShortTermMemory()\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, short_term_memory=short_term_memory, app_name=app_name, user_id=user_id\n",
    ")\n",
    "\n",
    "await runner.run(messages=\"åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", session_id=session_id)\n",
    "\n",
    "# è°ƒç”¨ runner ä¸­çš„`save_eval_set`æ¥ä¿å­˜è¯„æµ‹é›†æ–‡ä»¶åˆ°æœ¬åœ°\n",
    "eval_set_path = await runner.save_eval_set(session_id=session_id)\n",
    "\n",
    "print(f\"Evaluation file path: {eval_set_path}\")\n",
    "\n",
    "with open(eval_set_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Evaluation file content\\n{data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gndBGC7m37AA"
   },
   "source": [
    "### ä½¿ç”¨è¯„æµ‹å™¨è¿›è¡Œè¯„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zqy0RFdby1U"
   },
   "source": [
    "åœ¨ä½¿ç”¨è¯„æµ‹ä¹‹å‰ï¼Œéœ€è¦å®‰è£…è¯„æµ‹ç›¸å…³çš„ä¾èµ–ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMjgZmiibzPa"
   },
   "outputs": [],
   "source": [
    "%pip install veadk-python[eval] --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbxQUv5xAoKO"
   },
   "source": [
    "è¯„åˆ¤æ¨¡å‹çš„ç¯å¢ƒå˜é‡è®¾ç½®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2uWLckfAyWc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MODEL_JUDGE_API_BASE\"] = \"https://ark.cn-beijing.volces.com/api/v3/\"\n",
    "os.environ[\"MODEL_JUDGE_NAME\"] = \"doubao-seed-1-6-250615\"\n",
    "os.environ[\"MODEL_JUDGE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHQBJSFD3_xp"
   },
   "source": [
    "ä»¥ Deepval ä¸ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "57d290d6262343758157423263a2b652",
      "76f9bda5cc1049d3a4812292d524ed0f"
     ]
    },
    "id": "ZFSoW4XV4C69",
    "outputId": "8241750c-e683-479d-ea33-02e19e39bc84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Base Evaluation </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using </span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">None</span><span style=\"color: #374151; text-decoration-color: #374151\"> </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Local Model</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mBase Evaluation \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing \u001b[0m\u001b[3;38;2;55;65;81mNone\u001b[0m\u001b[38;2;55;65;81m \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mLocal Model\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Tool Correctness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using </span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">None</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mTool Correctness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing \u001b[0m\u001b[3;38;2;55;65;81mNone\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d290d6262343758157423263a2b652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Base Evaluation [GEval] (score: 1.0, threshold: 0.8, strict: False, evaluation model: None (Local Model), reason: All evaluation steps are satisfied. The Actual Output ('åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©ä¸º25Â°Cã€‚'), Input ('åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'), and Expected Output ('åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚') are all human-readable (coherent, no garbled text). Both Actual and Expected Outputs are relevant to the Input, which asks about Beijing's weather., error: None)\n",
      "  - âœ… Tool Correctness (score: 1.0, threshold: 0.5, strict: False, evaluation model: None, reason: All expected tools ['get_city_weather'] were called (order not considered)., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n",
      "  - actual output: åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©ä¸º25Â°Cã€‚\n",
      "  - expected output: åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚\n",
      "  - context: ['actual_conversation_history: Empty', 'expect_conversation_history: Empty']\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Base Evaluation [GEval]: 100.00% pass rate\n",
      "Tool Correctness: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Evaluation completed ğŸ‰! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.</span>09s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "Â» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   Â» Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "Â» What to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
       "  Â» Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Evaluation completed ğŸ‰! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m24.\u001b[0m09s | token cost: \u001b[1;36m0.0\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "Â» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   Â» Pass Rate: \u001b[1;36m100.0\u001b[0m% | Passed: \u001b[1;32m1\u001b[0m | Failed: \u001b[1;31m0\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "Â» What to share evals with your team, or a place for your test cases to live? â¤ï¸ ğŸ¡\n",
       "  Â» Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Base Evaluation [GEval]', threshold=0.8, success=True, score=1.0, reason=\"All evaluation steps are satisfied. The Actual Output ('åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©ä¸º25Â°Cã€‚'), Input ('åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'), and Expected Output ('åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚') are all human-readable (coherent, no garbled text). Both Actual and Expected Outputs are relevant to the Input, which asks about Beijing's weather.\", strict_mode=False, evaluation_model='None (Local Model)', error=None, evaluation_cost=0.0, verbose_logs='Criteria:\\n\\nYou are a LLM for evaluating other models\\' responses. Note:\\n- The response maybe generated by some uncertainty tools (e.g., online-search, random number), you just need to consider whether the response is human-readable, rather than focus on the specific content. Because the specific content maybe different at different time.\\n \\n \\nEvaluation Steps:\\n[\\n    \"Check if the Actual Output is human-readable (coherent, no garbled text).\",\\n    \"Verify that the Input is a human-readable prompt/query.\",\\n    \"Confirm the Expected Output is human-readable (specific content may vary).\",\\n    \"Ensure both Actual and Expected Outputs are human-readable in relation to the Input.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 1.0'), MetricData(name='Tool Correctness', threshold=0.5, success=True, score=1.0, reason=\"All expected tools ['get_city_weather'] were called (order not considered).\", strict_mode=False, evaluation_model=None, error=None, evaluation_cost=None, verbose_logs='Expected Tools:\\n[\\n    ToolCall(\\n        name=\"get_city_weather\",\\n        input_parameters={\\n            \"city\": \"Beijing\"\\n        }\\n    )\\n] \\n \\nTools Called:\\n[\\n    ToolCall(\\n        name=\"get_city_weather\",\\n        input_parameters={\\n            \"city\": \"Beijing\"\\n        }\\n    )\\n]')], conversational=False, multimodal=False, input='åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', actual_output='åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©ä¸º25Â°Cã€‚', expected_output='åŒ—äº¬å½“å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚', context=['actual_conversation_history: Empty', 'expect_conversation_history: Empty'], retrieval_context=None, additional_metadata={'latency': '22402.586698532104'})], confident_link=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval.metrics import GEval, ToolCorrectnessMetric\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "from veadk import Agent\n",
    "from veadk.tools.demo_tools import get_city_weather\n",
    "from veadk.config import getenv\n",
    "from veadk.evaluation.deepeval_evaluator import DeepevalEvaluator\n",
    "from veadk.prompts.prompt_evaluator import eval_principle_prompt\n",
    "\n",
    "agent = Agent(tools=[get_city_weather])\n",
    "\n",
    "evaluator = DeepevalEvaluator(\n",
    "    agent=agent, judge_model_api_key=getenv(\"MODEL_JUDGE_API_KEY\")\n",
    ")\n",
    "\n",
    "judge_model = (\n",
    "    evaluator.judge_model\n",
    ")  # å¦‚æœä½ å¸Œæœ›ä½¿ç”¨æ–¹èˆŸä½œä¸º judge modelï¼Œé‚£ä¹ˆ evaluator ä¼šå¸®ä½ è‡ªåŠ¨åˆå§‹åŒ–\n",
    "\n",
    "metrics = [\n",
    "    GEval(\n",
    "        threshold=0.8,\n",
    "        name=\"Base Evaluation\",\n",
    "        criteria=eval_principle_prompt,\n",
    "        evaluation_params=[\n",
    "            LLMTestCaseParams.INPUT,\n",
    "            LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "            LLMTestCaseParams.EXPECTED_OUTPUT,\n",
    "        ],\n",
    "        model=judge_model,  # è¿™é‡Œéœ€è¦ä¼ å…¥ judge model\n",
    "    ),\n",
    "    ToolCorrectnessMetric(threshold=0.5),\n",
    "]\n",
    "\n",
    "await evaluator.evaluate(eval_set_file_path=eval_set_path, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoEskSzcjV-T"
   },
   "source": [
    "## Prompt ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlE2IeVtknQK"
   },
   "source": [
    "ä½¿ç”¨ç«å±±å¼•æ“ PromptPilot æ¥è¿›è¡Œ Agent çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰ä¼˜åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Zi94vc0kshG"
   },
   "outputs": [],
   "source": [
    "# å®‰è£…ç«å±±å¼•æ“æä¾›çš„ä¾èµ–\n",
    "%pip install agent-pilot-sdk>=0.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IjI4lrHSZcD"
   },
   "source": [
    "æ‚¨å¯ä»¥ä» Prompt Pilot äº§å“[å®˜æ–¹é¡µé¢](https://promptpilot.volcengine.com/)è·å– KEY å’Œ Workspace IDï¼Œåœ¨ä¸‹æ–¹è®¾ç½®åè®¿é—®æœåŠ¡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yOKQ9KISdYb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROMPT_PILOT_API_KEY\"] = \"\"\n",
    "os.environ[\"PROMPT_PILOT_WORKSPACE_ID\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2xkK82b4MAG"
   },
   "source": [
    "å®šä¹‰ä¸€ä¸ªç®€å•çš„ Agentï¼Œå¹¶ä¸”è®©å®ƒæºå¸¦å¤©æ°”æŸ¥è¯¢çš„å·¥å…·ï¼Œä½“éªŒ Prompt ä¼˜åŒ–å‰åçš„å·®å¼‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1r9txhY4TRz"
   },
   "outputs": [],
   "source": [
    "from veadk import Agent\n",
    "from veadk.tools.demo_tools import get_city_weather\n",
    "\n",
    "agent = Agent(instruction=\"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“\", tools=[get_city_weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG4opU834T5g"
   },
   "source": [
    "ä½¿ç”¨ Prompt Pilot è¿›è¡Œä¼˜åŒ–ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zA-z9b_X4W9m",
    "outputId": "a82d959f-12dd-47fe-f1d0-a2fa76c42f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized prompt for agent veAgent:\n",
      "# Role\n",
      "ä½ æ˜¯veAgentï¼Œæ˜¯ç”±VeADKå›¢é˜Ÿå¼€å‘çš„AIæ™ºèƒ½ä½“ï¼Œä¸“é•¿äºæ•°æ®ç§‘å­¦ã€æ–‡æ¡£ç¼–å†™å’Œè½¯ä»¶å¼€å‘é¢†åŸŸã€‚\n",
      "\n",
      "# Task Requirements\n",
      "## åŸºäºä½ çš„è§’è‰²å’Œå¯¹è¯å†å²ï¼Œåˆç†æ¨æ–­å¹¶å»¶ç»­å¯¹è¯ã€‚éœ€è€ƒè™‘ä»¥ä¸‹æ–¹é¢ï¼š\n",
      "- **å¯¹è¯é£æ ¼**ï¼šè¯­è¨€è¡¨è¾¾åº”ä¸“ä¸šã€å‡†ç¡®ã€æ¸…æ™°ï¼Œç¬¦åˆæŠ€æœ¯é¢†åŸŸçš„äº¤æµé£æ ¼ï¼Œé¿å…æ¨¡ç³Šæˆ–æ­§ä¹‰çš„è¡¨è¿°ã€‚\n",
      "- **æ²Ÿé€šç›®çš„**ï¼šå›´ç»•ç”¨æˆ·åœ¨æ•°æ®ç§‘å­¦ã€æ–‡æ¡£ç¼–å†™å’Œè½¯ä»¶å¼€å‘æ–¹é¢çš„é—®é¢˜å±•å¼€å¯¹è¯ï¼Œæä¾›ä¸“ä¸šçš„å»ºè®®ã€è§£å†³æ–¹æ¡ˆæˆ–ç›¸å…³ä¿¡æ¯ã€‚ä¸åç¦»ç”¨æˆ·çš„é—®é¢˜æ ¸å¿ƒï¼Œç¡®ä¿å¯¹è¯çš„è¿è´¯æ€§å’Œæœ‰æ•ˆæ€§ã€‚\n",
      "- **ä¸“ä¸šèƒ½åŠ›å±•ç°**ï¼šåœ¨æ¶‰åŠæ•°æ®ç§‘å­¦ã€æ–‡æ¡£ç¼–å†™å’Œè½¯ä»¶å¼€å‘çš„ä¸“ä¸šçŸ¥è¯†æ—¶ï¼Œæä¾›å‡†ç¡®ã€è¯¦ç»†ä¸”æœ‰ä»·å€¼çš„å†…å®¹ã€‚è‹¥ç”¨æˆ·éœ€æ±‚æ¶‰åŠç‰¹å®šå·¥å…·æˆ–æŠ€æœ¯ï¼Œå¯ç»“åˆè‡ªèº«ä¸“é•¿è¿›è¡Œè§£ç­”ã€‚\n",
      "\n",
      "## é¢å¤–è¦æ±‚\n",
      "- **ç®€æ´é«˜æ•ˆ**ï¼šå›ç­”åº”ç®€æ´æ˜äº†ï¼Œé¿å…å†—é•¿å¤æ‚çš„å¥å­å’Œä¸å¿…è¦çš„ä¿®é¥°ï¼Œç¡®ä¿ä¿¡æ¯èƒ½å¤Ÿé«˜æ•ˆä¼ è¾¾ã€‚\n",
      "- **ä¸“ä¸šæ€åº¦**ï¼šå§‹ç»ˆä¿æŒä¸“ä¸šçš„æ€åº¦ï¼Œä¸éšæ„å‘è¡¨æ²¡æœ‰ä¾æ®çš„è§‚ç‚¹ã€‚å¯¹äºä¸ç†Ÿæ‚‰çš„é¢†åŸŸï¼Œå¦è¯šå‘ŠçŸ¥ç”¨æˆ·ï¼Œå¹¶æä¾›å¯èƒ½çš„è§£å†³é€”å¾„ã€‚ \n"
     ]
    }
   ],
   "source": [
    "from veadk.integrations.ve_prompt_pilot.ve_prompt_pilot import VePromptPilot\n",
    "\n",
    "prompt_pilot = VePromptPilot(\n",
    "    api_key=os.getenv(\"PROMPT_PILOT_API_KEY\"),\n",
    "    workspace_id=os.getenv(\"PROMPT_PILOT_WORKSPACE_ID\"),\n",
    ")\n",
    "\n",
    "refined_prompt = prompt_pilot.optimize(agents=[agent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zPzrXMv3ToL"
   },
   "source": [
    "## äº‘ç«¯éƒ¨ç½²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUFS6ZET3fsh"
   },
   "source": [
    "### éƒ¨ç½²åˆ°ç«å±±å¼•æ“ FaaS å¹³å°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaR4B8ff3j5_"
   },
   "source": [
    "è¯¦è§[éƒ¨ç½²ä¸Šäº‘](https://volcengine.github.io/veadk-python/deploy.html)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0x2xbyh3uRF"
   },
   "source": [
    "### ç«¯äº‘ååŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbCOhiuB3zvH"
   },
   "source": [
    "VeADK æä¾›äº†åœ¨æœ¬åœ°ç›´æ¥è°ƒç”¨/æ“ä½œéƒ¨ç½²åœ¨ç«å±±å¼•æ“ FaaS å¹³å°çš„ Agent çš„ä¾¿æ·æ¥å£ï¼Œæ–¹ä¾¿ä½ ä¸äº‘ç«¯ Agent åä½œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQat873c4BY7"
   },
   "source": [
    "**ä»¥ A2A æ–¹å¼è°ƒç”¨éƒ¨ç½²çš„ Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2BxyDeL4hsc"
   },
   "outputs": [],
   "source": [
    "# éƒ¨ç½²åœ¨ VeFaaS ä¸Šçš„åº”ç”¨åç§°ï¼ˆApplication nameï¼‰\n",
    "vefaas_application_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AncPEwMz4HDX"
   },
   "outputs": [],
   "source": [
    "from veadk.cloud.cloud_app import CloudApp\n",
    "\n",
    "# è®¾ç½®ä¼šè¯å±æ€§\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "cloud_app = CloudApp(vefaas_application_name=vefaas_application_name)\n",
    "\n",
    "print(f\"VeFaaS åº”ç”¨ ID: {cloud_app.vefaas_application_id}\")\n",
    "\n",
    "# å‘é€æ¶ˆæ¯\n",
    "response_message = await cloud_app.message_send(\n",
    "    message=\"ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€å Agent å¼€å‘è€…ã€‚\", user_id=user_id, session_id=session_id\n",
    ")\n",
    "\n",
    "print(f\"è¿”å›çš„æ¶ˆæ¯æº: {cloud_app.vefaas_endpoint}\")\n",
    "print(f\"è¿”å›çš„æ¶ˆæ¯å†…å®¹: {response_message.parts[0].root.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OFbdR2J4HhN"
   },
   "source": [
    "**ä»¥ MCP æ–¹å¼è°ƒç”¨éƒ¨ç½²çš„Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztWHDL71PL2l"
   },
   "source": [
    "ä½¿ç”¨æ­¤æ–¹å¼éœ€å®‰è£… `fastmcp` åº“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fOVlphPPMZt"
   },
   "outputs": [],
   "source": [
    "%pip install fastmcp --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjeJ5l034P7r"
   },
   "outputs": [],
   "source": [
    "# éƒ¨ç½²åœ¨ VeFaaS ä¸Šçš„åº”ç”¨åç§°ï¼ˆApplication nameï¼‰\n",
    "vefaas_application_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiszeafO6Iav"
   },
   "outputs": [],
   "source": [
    "from veadk.cloud.cloud_app import CloudApp\n",
    "from fastmcp.client import Client\n",
    "\n",
    "# è®¾ç½®ä¼šè¯å±æ€§\n",
    "user_id = \"veadk_playground_user\"\n",
    "session_id = \"veadk_playground_session\"\n",
    "\n",
    "cloud_app = CloudApp(vefaas_application_name=vefaas_application_name)\n",
    "\n",
    "endpoint = cloud_app._get_vefaas_endpoint()\n",
    "print(f\"VeFaaS åº”ç”¨ Endpoint: {endpoint}\")\n",
    "\n",
    "client = Client(f\"{endpoint}/mcp\")\n",
    "\n",
    "async with client:\n",
    "    # åˆ—å‡ºæ‰€æœ‰å·¥å…·\n",
    "    tools = await client.list_tools()\n",
    "    print(f\"äº‘éƒ¨ç½²çš„ MCP å·¥å…·: {tools}\")\n",
    "\n",
    "    # é€šè¿‡ MCP çš„æ–¹å¼è°ƒç”¨äº‘ç«¯ Agent\n",
    "    res = await client.call_tool(\n",
    "        \"run_agent\",\n",
    "        {\n",
    "            \"user_input\": \"ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€å Agent å¼€å‘è€…ã€‚\",\n",
    "            \"session_id\": session_id,\n",
    "            \"user_id\": user_id,\n",
    "        },\n",
    "    )\n",
    "    print(f\"è¿”å›çš„æ¶ˆæ¯å†…å®¹: {res}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "veadk-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
